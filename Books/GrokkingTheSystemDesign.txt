1. Ask Requirements Clarifications 
2. Estimate the scale of the system ( scaling, partitioning, load balancing, caching)
How much storage will we need? We may have different storage requirements 
for users if they can have photos / videos (Content Manager System)
3. Systerm interface definition: Define what APIs are expected from the system
(postTweet, generateTimeline, markFavoriteTwee) 
4. Define the data model. The candidate should be able to identify various 
entities of the system, how they interact, and different aspects of data management
like storage (exL which database system do we use?)
5. High level design 
6. Detailed design 
7. Identifying and resolving bottlenecks 

If you anticipate on storing billions of rows, you do not need a relationship between objects 
a NoSQL store like DynamoDB, Cassandra, RISK is the better choice. 

Question for facebook: If we activate notifications on our phones, does this create 
the pull model for messenging where the user will periodically ping the server if there
are any new messages for them 

How to maintain an open connection with the server? HttpLongPolling or Websockets 

Facebook uses HBase. Hbase is a column oriented key-value NoSQL database that can
store multiple values against one key into multiple rows. HBase is modeled after
Google's BigTable and runs on top of HDFS. HBase groups data together to 
store new data in a memory buffer, and once the buffer is full it will
dump the data to the disk. Hbase is efficient in storing variable sized data 

Load balancing spreads traffic across a cluster of servers to improve
responsiveness and availability of applications or databases 
A load balancer reduces individual server load and prevents any one 
application server from becoming a single point of failure, thus improving overall 
application availability and responsiveness 
-Server is fast and uninterrupted. Requests are directly passed on to a more 
readily available resource 
-Service providers experience less downtime and higher throughput
-Handles traffic bottlenecks 
-Instead of single deice performing a lot of work, load balancing has several
devices perform a little bit of work 

Load balancing algorithms: least response time method, least bandwidth method, 
round robin method, weighted round robin method 
Round robin method: this method cycles through a list of servers and sends each new request to the next server
When it reaches the end of the list it starts over at the beginning. It is the most useful when the servers 
are of equal specification and there are not many persistent connections 
Weghted Round robin: designed to better handle servers with different processing capabilities 
Each server is assigned a weight (an integer value that indicates the processing capacity) 
Servers with higher weights receive new connections before those with less weights and servers 
with higher weights get more connections than those with less weights 

Redundant load balancers: load balancer can be a single point of failure, a second load balancer can be 
connecte to the first to form a cluster. Each LB monitors the health of the other and both of them
are equally capable of serving traffic and failure detection

CAP Theorem: Impossible for a distributed system to provide more than two of the three 
guarantees: Consistency, Availability, Partition tolerance 
Consistency: update several nodes before read. All nodes see the same data 
Availability: every request gets a success or failure. Achieved by data replication across different servers 
Partition Tolerance: System works despite a failed message or failure 
System can sustain any amount of network failure that does not result in a failure of the entire network 
Data is replicated across combinations of nodes and networks to keep the system up 


